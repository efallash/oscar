# OSCAR
Repository for OSCAR (Open Source Cognitive Applied Robot)

OSCAR is a robotic platform based on the [Thor robot arm](https://github.com/AngelLM/Thor) created by AngelLM. It is designed to be applied in cogntive learning and has been integrated with the *Multilevel Darwinist Brain* [1] cognitive architecture. Currently, it is implemented only in the Gazebo simulator.

The implementation of the Thor arm in gazebo simulator is in [this repo](https://github.com/efallash/thor_simulator)

<img src="docs/oscar_gazebo.jpg" width="400" align="center">

OSCAR is composed of two Thor arms, and simulated cameras ([Realsense D435](https://www.intelrealsense.com/depth-camera-d435/) and [RPi Camera Module V2](https://www.raspberrypi.org/documentation/hardware/camera/)). It is implemented using ROS and MoveIt, which allows a modular software architecture for easy integration with other cognitive frameworks. 

The ROS architecture of OSCAR is shown in the following diagram:

<img src="docs/oscar_diagram.png" width="1200" align="center">


## Repository index


 - oscar_bringup: Launch files to start the simulation.
 - oscar_common: Command server code and a manipulation test called change_hands.
 - oscar_description: Xacro description files of the robot.
 - oscar_gazebo: World and model files for gazebo.
 - oscar_mdb: Code, configuration and launch files for oscar_mdb_server.
 - oscar_moveit_config: MoveIt configuration files generated by the setup assistant.
 - oscar_msgs: Message files for the services.
 - oscar_perception: Code of the perception server.
 - oscar_tests: Multiple scripts that run precision, manipulation and perception tests.


## Installation

The following installation guide assumes a clean installation of Ubuntu 20.4 (Focal Fossa). 

### Required packages

Install ROS noetic following the instructions [here](http://wiki.ros.org/noetic/Installation/Ubuntu)

Install MoveIt 1:
    
    sudo apt install ros-noetic-moveit

Install ROS Control:

    sudo apt-get install ros-noetic-ros-control ros-noetic-ros-controllers

Install catkin_tools (RECOMMENDED):

    sudo apt-get install python3-catkin-tools
    sudo apt install python3-catkin-lint python3-pip
    pip3 install osrf-pycommon

### Required Python packages

The required python packages can be installed using pip3:

Pandas
  
    pip3 install pandas

Scikit-Image

    pip3 install scikit-image

CameraTransform

    pip3 install cameratransform

The following Python packages are required by MDB:

Yamlloader

    pip3 install yamlloader

Tensorflow

    pip3 install --user --upgrade tensorflow

Dash and Cytoscape

    pip3 install dash
    pip3 install dash-cytoscape

Networkx

    pip3 install networkx

### Creating a catkin workspace

ROS packages must be contained in a workspace to work properly. To create a workspace using catkin tools first you must create a empty folder in the home folder (recommended) generally called catkin_ws with a src folder:

    cd
    mkdir catkin_ws/src

Initialize the workspace:

    cd catkin_ws/
    catkin init
    catkin build

To use the workspace you must source its setup file everytime you open a terminal:

    source catkin_ws/devel/setup.bash

Alternatively, you can add this line to .bashrc to avoid sourcing manually:

    cd
    echo "source ~/catkin_ws/devel/setup.bash" >> ~/.bashrc
    source ~/.bashrc

### Downloading the source code

Download this repository and the [thor_simulator](https://github.com/efallash/thor_simulator) in the src folder of your workspace

    cd
    cd catkin_ws/src/
    git clone https://github.com/efallash/oscar.git
    git clone https://github.com/efallash/thor_simulator.git

The MDB code is not published yet, you can contact the [GII](https://github.com/GII) if you need access. 



## Usage


### Robot bringup
~Launch del robot y los parámetros posibles~


### ROS API
~Explicar los topics y servicios disponibles~


### Running tests
~Launch de los tests que existen y parámetros~
~Se podría separar para cada test~


### Executing cognitive experiments
~Launch del test y explicación del config.yaml~



## References

[1] J. A. Becerra, A. Romero, F. Bellas, and R. J. Duro, “Motivational engine andlong-term memory coupling within a cognitive architecture for lifelong open-ended learning,” *Neurocomputing*, 11 2020. doi: https://doi.org/10.1016/j.neucom.2019.10.124


